#!/usr/bin/env python3
import pandas as pd
import json

def group_consecutive(ranks):
    """
    Given a sorted list of rank numbers, group consecutive numbers into ranges.
    Returns a list of strings like "801-805", "830-840", etc.
    """
    if not ranks:
        return []
    
    ranges = []
    start = prev = ranks[0]
    for rank in ranks[1:]:
        if rank == prev + 1:
            prev = rank
        else:
            if start == prev:
                ranges.append(f"{start}")
            else:
                ranges.append(f"{start}-{prev}")
            start = prev = rank
    if start == prev:
        ranges.append(f"{start}")
    else:
        ranges.append(f"{start}-{prev}")
    return ranges

def get_allowed_keys(csv_file='top_1000_twitch.csv'):
    """
    Reads the CSV and returns a dictionary mapping key -> rank.
    Keys are generated by removing spaces and converting to uppercase.
    """
    try:
        df = pd.read_csv(csv_file)
    except Exception as e:
        print("Error reading CSV file:", e)
        return {}
    
    allowed = {row['Name'].replace(" ", "").upper(): int(row['Rank']) for _, row in df.iterrows()}
    return allowed

def clean_and_check_json(json_file, csv_file='top_1000_twitch.csv'):
    """
    For the given JSON file:
      - Prints keys whose value is an empty list.
      - Prints keys that are not in the allowed list from the CSV.
      - Removes entries with empty lists AND entries whose keys are not in the CSV.
      - Writes the changes back to the JSON file.
      - Checks which CSV streamers (by rank) are missing in the cleaned JSON, grouping consecutive ranks.
    """
    allowed_keys_dict = get_allowed_keys(csv_file)
    allowed_keys = set(allowed_keys_dict.keys())

    # Load the JSON file
    try:
        with open(json_file, 'r') as f:
            data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"Error reading {json_file}: {e}")
        return

    # 1. Identify and print keys with empty list values.
    empty_keys = [key for key, value in data.items() if value == []]
    print(f"\n[{json_file}] Keys with empty lists:")
    print(empty_keys)

    # 2. Identify and print keys in JSON that are not in the allowed CSV list.
    extra_keys = [key for key in data.keys() if key not in allowed_keys]
    print(f"\n[{json_file}] Keys that are NOT in top_1000_twitch.csv:")
    print(extra_keys)

    # 3. Remove entries with empty lists.
    data_cleaned = {key: value for key, value in data.items() if value != []}
    # Now remove entries not found in the allowed keys.
    data_cleaned = {key: value for key, value in data_cleaned.items() if key in allowed_keys}

    # Write the updated data back to the JSON file.
    with open(json_file, 'w') as f:
        json.dump(data_cleaned, f, indent=4)
    print(f"\n[{json_file}] has been updated by removing entries with empty lists and extra keys.")

    # 4. Determine which CSV keys (by rank) are missing in the cleaned JSON.
    current_keys = set(data_cleaned.keys())
    missing_ranks = [allowed_keys_dict[key] for key in allowed_keys if key not in current_keys]
    missing_ranks.sort()
    missing_ranges = group_consecutive(missing_ranks)
    print(f"\n[{json_file}] CSV streamers (by rank) missing from the JSON:")
    print(missing_ranges)

if __name__ == "__main__":
    print("Processing reddit.json...")
    clean_and_check_json('reddit.json', 'top_1000_twitch.csv')
    
    print("\nProcessing wikipage2.json...")
    clean_and_check_json('wikipage2.json', 'top_1000_twitch.csv')

    print("\nProcessing wikipage2.json...")
    clean_and_check_json('twitter.json', 'top_1000_twitch.csv')

    print("\nProcessing wikipage2.json...")
    clean_and_check_json('random.json', 'top_1000_twitch.csv')


